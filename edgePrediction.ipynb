{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251590e0-6fb8-483a-bd90-d38b6660220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorForLanguageModeling\n",
    "import datasets\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c562e1-e352-4c56-aa28-1f213599a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd1630-ef7d-40c4-85df-b3ea77dad60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e1ffb-2ad8-40a5-8619-435f53de64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "newpath = 'experiments/EXP' + EXP\n",
    "\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "if not os.path.exists(newpath + 'model'):\n",
    "    os.makedirs(newpath + 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b50ed-01bb-4c32-9de4-e2fc48614962",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ac209-a8dd-45b3-8faa-39fbf7e2c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph = nx.read_graphml(\"../graph.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09609d-ac02-4404-a5b2-7b2c30a5b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee93733-a852-4ebf-8c9b-1232fb3935c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = nx.community.louvain_communities(graph, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794afe86-96ce-46c6-92a0-571e1440961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "\n",
    "for c in communities:\n",
    "    lengths.append(len(c))\n",
    "\n",
    "lengths = sorted(lengths, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b4ec6-1c81-488c-b8b1-37f8f0a3a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "for e in graph.edges(data=True):\n",
    "    s.add(e[2]['display_relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb3801-a510-4b97-8d2a-37ba3fa14e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b5bd1-ffbb-4de7-bb52-80132c6eaf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "for n in graph.nodes(data=True):\n",
    "    s.add(n[1]['node_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96baf5b8-7ec3-45f6-8ca1-996794efa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5456ee-38de-4af0-9164-62f1182a1ffd",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbd31d-5d5b-407a-988c-c60b029bef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "m_n_values = []\n",
    "\n",
    "for comm in communities:\n",
    "    sub = graph.subgraph(comm)\n",
    "    if not nx.is_connected(sub):\n",
    "        c_comp = list(nx.connected_components(sub))\n",
    "        for c in c_comp:\n",
    "            communities.append(c)\n",
    "        continue\n",
    "\n",
    "    m = int(nx.diameter(sub))\n",
    "\n",
    "    if m > 0:\n",
    "        n = round(sub.number_of_nodes())\n",
    "\n",
    "        if n == 0:\n",
    "            n = 1\n",
    "            \n",
    "        random_path = nx.generate_random_paths(sub, n, path_length=m, seed=42)\n",
    "        paths = []\n",
    "        for rp in random_path:\n",
    "            paths.append(rp)\n",
    "        l = len(paths)\n",
    "        if l > 0:\n",
    "            train_set.append(paths)\n",
    "            m_n = (m, n)\n",
    "            m_n_values.append(m_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684c9c4-9145-4084-aac3-01882646a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_n_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106254ab-db88-482a-a199-af1d5676655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/m_n_values.pkl', 'wb') as f:\n",
    "    pickle.dump(m_n_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be25086-ac7c-4213-aa28-faaba885c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b689012-bdef-4ab1-8069-60cf689be9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5424d-d08c-4815-ad47-c5ce232a705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "triples = set()\n",
    "\n",
    "for walks in train_set:\n",
    "    for walk in walks:\n",
    "        chat = []\n",
    "\n",
    "        system = {\"role\": \"system\", \"content\": \"You are a chatbot that has to predict the relationship between nodes.\"}\n",
    "        chat.append(system)\n",
    "        for i in range(len(walk)-1):\n",
    "            rel = graph[walk[i]][walk[i+1]]['display_relation']\n",
    "            a = graph.nodes[walk[i]]['node_name']\n",
    "            b = graph.nodes[walk[i+1]]['node_name']\n",
    "            triple = (a, rel, b)\n",
    "            triples.add(triple)\n",
    "            \n",
    "            user = \"Which is the relationship between the node '\" + a + \"' and the node '\" + b + \"'?\"\n",
    "            assistant = rel\n",
    "            \n",
    "            message = {}\n",
    "            message[\"role\"] = \"user\"\n",
    "            message[\"content\"] = user\n",
    "            chat.append(message)\n",
    "\n",
    "            message = {}\n",
    "            message[\"role\"] = \"assistant\"\n",
    "            message[\"content\"] = assistant\n",
    "            chat.append(message)\n",
    "\n",
    "        if chat not in train_dataset:\n",
    "            train_dataset.append(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094a047-0d44-4394-b7aa-843305752cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f94188-9d02-430b-a74b-51b168c88ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/train_val_triples.pkl', 'wb') as file1:\n",
    "    pickle.dump(triples, file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0afc2-0250-4cf0-82c1-105db8246a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5be901-a31b-4766-925a-d3c38faf4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea7010-9ccd-497e-be29-73c5d9237082",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(len(train_dataset)/10)\n",
    "val_dataset = train_dataset[:l]\n",
    "train_dataset = train_dataset[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452b7a5-a413-4af1-a70b-530ec9e404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a5e8e-2e30-4f15-9892-6f224365bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/train_dataset.pkl', 'wb') as file1:\n",
    "    pickle.dump(train_dataset, file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ba147-4282-47ff-b26d-19dd262cfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/val_dataset.pkl', 'wb') as file2:\n",
    "    pickle.dump(val_dataset, file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c21c907-953b-4943-8a7c-a8e2f17f1b49",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d36da-8a45-4141-bdff-b5e8ebc7f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_triples = set()\n",
    "edges = list(graph.edges(data=True))\n",
    "\n",
    "while len(test_triples) < 1500:\n",
    "    e = random.randint(0, 4049642)\n",
    "    edge = edges[e]\n",
    "    node1 = graph.nodes[edge[0]]['node_name']\n",
    "    node2 = graph.nodes[edge[1]]['node_name']\n",
    "    triple = (node1, edge[2]['display_relation'], node2)\n",
    "    if triple not in triples:\n",
    "        test_triples.add(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e6912-62f5-42de-b85b-f67b6270b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475686e2-19be-4c0a-b5c7-2e9535755e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = triples & test_triples\n",
    "len(abc) # Numero di triple in comune tra train e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b50c7-4cb8-4fc0-b917-03675019bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/test_triples.pkl', 'wb') as file1:\n",
    "    pickle.dump(test_triples, file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb9a24-8845-4216-8c19-76892fb3bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "ground_truth = []\n",
    "\n",
    "for t in test_triples:\n",
    "    chat = []\n",
    "    system = {\"role\": \"system\", \"content\": \"You are a chatbot that has to predict the relationship between nodes.\"}\n",
    "    user = {\"role\": \"user\", \"content\": \"Which is the relationship between the node '\" + t[0] + \"' and the node '\" + t[2] + \"'?\"}\n",
    "    chat.append(system)\n",
    "    chat.append(user)\n",
    "    test_dataset.append(chat)\n",
    "\n",
    "    assistant = {\"role\": \"assistant\", \"content\": t[1]}\n",
    "    chat.append(assistant)\n",
    "    ground_truth.append(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cddc7e-68af-4661-bd91-ddda124de4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/test_dataset.pkl', 'wb') as file1:\n",
    "    pickle.dump(test_dataset, file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da78f4-71f6-4e03-ae1c-1f1606bfec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/ground_truth.pkl', 'wb') as file1:\n",
    "    pickle.dump(ground_truth, file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf9ee7-92f2-4163-b12b-961bc7bbdebe",
   "metadata": {},
   "source": [
    "### Acquisizione modello e dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb2116-2435-4a95-b6ce-16eb81bb3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/train_dataset.pkl', 'rb') as file:\n",
    "    train_dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9d109-3e3f-4434-980a-f1beb20d516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/val_dataset.pkl', 'rb') as file:\n",
    "    val_dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41d426-561e-4d1b-81ff-f7c3f94f9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sapienzanlp/Minerva-350m-base-v1.0\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sapienzanlp/Minerva-350m-base-v1.0\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a395cb-ef80-4e33-a0ba-43e745d5248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset1 = Dataset.from_dict({\"chat\": train_dataset})\n",
    "dataset1 = dataset1.map(lambda x: {\"formatted_chat\": tokenizer.apply_chat_template(x[\"chat\"], tokenize=True, add_generation_prompt=False)})\n",
    "\n",
    "dataset2 = Dataset.from_dict({\"chat\": val_dataset})\n",
    "dataset2 = dataset2.map(lambda x: {\"formatted_chat\": tokenizer.apply_chat_template(x[\"chat\"], tokenize=True, add_generation_prompt=False)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc8346-c18d-4ebe-9272-121ff75c973f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590def80-abf3-4bf5-b8d0-6018a0f75b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='outputs',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=250,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    do_eval=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    eval_strategy=\"steps\",\n",
    "    logging_steps=250,\n",
    "    warmup_steps=50,\n",
    "    prediction_loss_only=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset1['formatted_chat'],\n",
    "    eval_dataset=dataset2['formatted_chat'],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7e2b2-4d78-46aa-9a48-17fc9b90ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('experiments/EXP' + EXP + 'model')\n",
    "tokenizer.save_pretrained('experiments/EXP' + EXP + 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ae114-c204-4860-97ed-fb71f82f9211",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403fbc4-16f9-4b08-812c-33853782c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af420a52-0df4-423e-ac5e-0f510679deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('experiments/EXP' + EXP + 'model')\n",
    "final_model = AutoModelForCausalLM.from_pretrained('experiments/EXP' + EXP + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a4f6c-1545-4bbe-9477-291563655f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/test_dataset.pkl', 'rb') as file:\n",
    "    test_dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6e7a3-144b-4627-a352-2167b9c6e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ft = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    prompt = []\n",
    "    ground_truth = ''\n",
    "    for m in test_dataset[i]:\n",
    "        if m['role'] != 'assistant':\n",
    "            prompt.append(m)\n",
    "        else:\n",
    "            ground_truth = m['content']\n",
    "    inputs = tokenizer.apply_chat_template(prompt, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
    "    inputs = {k: v for k, v in inputs.items()}\n",
    "\n",
    "    if ground_truth != '':\n",
    "        tok = tokenizer(ground_truth, return_tensors=\"pt\")\n",
    "        out = final_model.generate(**inputs, max_new_tokens=len(tok['input_ids'][0]), do_sample=True, num_return_sequences=10)\n",
    "        generations = []\n",
    "        for j in range(10):\n",
    "            gen = tokenizer.decode(out[j][len(inputs[\"input_ids\"][0]):])\n",
    "            generations.append(gen)\n",
    "    \n",
    "        t = (test_dataset[i], generations)\n",
    "        post_ft.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced65462-ed91-45d8-872b-061fbfe0d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/results_postft.pkl', 'wb') as file:\n",
    "    pickle.dump(post_ft, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14f42a-1535-4daf-a098-223682317a35",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b14a38-6a79-43e3-8bf4-0db36781d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/EXP' + EXP + '/results_postft.pkl', 'rb') as file:\n",
    "    post_ft = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02872ac3-c11e-4be6-9b12-ff453ed15e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "for d, g in post_ft:\n",
    "    gen = []\n",
    "    for pred in g:\n",
    "        gen.append(pred.strip())\n",
    "    clean.append((d, gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f00e24-580d-46f8-a641-d3f0ffea1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr_list = []\n",
    "for d, g in clean:\n",
    "    c = d[2]['content']\n",
    "    try:\n",
    "        mrr = g.index(c)\n",
    "    except ValueError:\n",
    "        mrr = 9\n",
    "    mrr_list.append(1/mrr)\n",
    "\n",
    "mrr_mean = sum(mrr_list) / len(mrr_list)\n",
    "mrr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372dbf8-6410-431a-af4b-8791d281d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit1_list = []\n",
    "for d, g in clean:\n",
    "    c = d[2]['content']\n",
    "    if c == g[0]:\n",
    "        hit1_list.append(1)\n",
    "    else:\n",
    "        hit1_list.append(0)\n",
    "\n",
    "hit1_mean = sum(hit1_list) / len(hit1_list)\n",
    "\n",
    "hit3_list = []\n",
    "for d, g in clean:\n",
    "    c = d[2]['content']\n",
    "    if c in g[:3]:\n",
    "        hit3_list.append(1)\n",
    "    else:\n",
    "        hit3_list.append(0)\n",
    "\n",
    "hit3_mean = sum(hit3_list) / len(hit3_list)\n",
    "\n",
    "hit5_list = []\n",
    "for d, g in clean:\n",
    "    c = d[2]['content']\n",
    "    if c in g[:5]:\n",
    "        hit5_list.append(1)\n",
    "    else:\n",
    "        hit5_list.append(0)\n",
    "\n",
    "hit5_mean = sum(hit5_list) / len(hit5_list)\n",
    "\n",
    "hit7_list = []\n",
    "for d, g in clean:\n",
    "    c = d[2]['content']\n",
    "    if c in g[:7]:\n",
    "        hit7_list.append(1)\n",
    "    else:\n",
    "        hit7_list.append(0)\n",
    "\n",
    "hit7_mean = sum(hit7_list) / len(hit7_list)\n",
    "\n",
    "hit10_list = []\n",
    "for d, g in clean:\n",
    "    c = d[2]['content']\n",
    "    if c in g:\n",
    "        hit10_list.append(1)\n",
    "    else:\n",
    "        hit10_list.append(0)\n",
    "\n",
    "hit10_mean = sum(hit10_list) / len(hit10_list)\n",
    "\n",
    "print(\"Hit@1 = \" + str(hit1_mean))\n",
    "print(\"Hit@3 = \" + str(hit3_mean))\n",
    "print(\"Hit@5 = \" + str(hit5_mean))\n",
    "print(\"Hit@7 = \" + str(hit7_mean))\n",
    "print(\"Hit@10 = \" + str(hit10_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
